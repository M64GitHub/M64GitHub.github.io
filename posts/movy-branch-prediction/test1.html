<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>How Building a Terminal Graphics Engine Taught Me About CPU Branch Prediction</title>
	<style>
		@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=JetBrains+Mono&display=swap');

		* {
			margin: 0;
			padding: 0;
			box-sizing: border-box;
		}

		body {
			background: #2b2b2b;
			color: #d4d4d4;
			font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
			line-height: 1.7;
			padding: 20px;
		}

		.container {
			max-width: 800px;
			margin: 0 auto;
			background: #363636;
			padding: 80px 60px;
			border-radius: 4px;
		}

		h1 {
			font-size: 2.5em;
			font-weight: 700;
			color: #88c0d0;
			margin-bottom: 20px;
			line-height: 1.3;
			letter-spacing: -0.5px;
		}

		h2 {
			font-size: 1.8em;
			font-weight: 700;
			color: #81a1c1;
			margin-top: 50px;
			margin-bottom: 20px;
			padding-bottom: 8px;
			border-bottom: 1px solid #4c566a;
		}

		h3 {
			font-size: 1.4em;
			font-weight: 600;
			color: #b48ead;
			margin-top: 35px;
			margin-bottom: 15px;
		}

		p {
			margin-bottom: 18px;
			color: #d4d4d4;
		}

		strong {
			color: #ebcb8b;
			font-weight: 600;
		}

		em {
			color: #a3be8c;
			font-style: italic;
		}

		a {
			color: #88c0d0;
			text-decoration: none;
			border-bottom: 1px solid transparent;
			transition: border-bottom 0.2s;
		}

		a:hover {
			border-bottom: 1px solid #88c0d0;
		}

		code {
			background: #2e3440;
			color: #d08770;
			padding: 3px 6px;
			border-radius: 3px;
			font-family: 'JetBrains Mono', 'Consolas', 'Monaco', monospace;
			font-size: 0.9em;
		}

		pre {
			background: #2e3440;
			border-left: 3px solid #5e81ac;
			border-radius: 4px;
			padding: 20px;
			overflow-x: auto;
			margin: 25px 0;
		}

		pre code {
			background: none;
			padding: 0;
			color: #d8dee9;
			display: block;
			font-size: 0.85em;
			line-height: 1.6;
		}

		.subtitle {
			font-size: 1.2em;
			color: #9a9a9a;
			margin-bottom: 30px;
			font-weight: 400;
		}

		hr {
			border: none;
			height: 1px;
			background: #4c566a;
			margin: 40px 0;
		}

		ul,
		ol {
			margin-left: 25px;
			margin-bottom: 18px;
		}

		li {
			margin-bottom: 8px;
			color: #d4d4d4;
		}

		.image-placeholder {
			background: #2e3440;
			border: 2px dashed #5e81ac;
			padding: 50px 20px;
			text-align: center;
			margin: 25px 0;
			border-radius: 4px;
			color: #888;
			font-style: italic;
		}

		img {
			max-width: 100%;
			height: auto;
			display: block;
			margin: 25px auto;
			border-radius: 4px;
		}

		blockquote {
			border-left: 4px solid #5e81ac;
			padding-left: 20px;
			margin: 25px 0;
			color: #9a9a9a;
			font-style: italic;
		}

		table {
			width: 100%;
			border-collapse: collapse;
			margin: 25px 0;
			font-size: 0.9em;
		}

		th,
		td {
			padding: 12px;
			text-align: left;
			border: 1px solid #4c566a;
		}

		th {
			background: #2e3440;
			color: #88c0d0;
			font-weight: 600;
		}

		td {
			background: #363636;
		}

		tr:hover td {
			background: #3a3a3a;
		}

		.footer {
			margin-top: 60px;
			padding-top: 30px;
			border-top: 1px solid #4c566a;
			color: #888;
			font-style: italic;
			text-align: center;
		}

		/* Scrollbar styling */
		::-webkit-scrollbar {
			width: 10px;
			height: 10px;
		}

		::-webkit-scrollbar-track {
			background: #2b2b2b;
		}

		::-webkit-scrollbar-thumb {
			background: #4c566a;
			border-radius: 5px;
		}

		::-webkit-scrollbar-thumb:hover {
			background: #5e81ac;
		}

		@media (max-width: 768px) {
			.container {
				padding: 40px 30px;
			}

			h1 {
				font-size: 2em;
			}

			h2 {
				font-size: 1.5em;
			}

			pre {
				padding: 15px;
			}
		}
	</style>
</head>

<body>
	<div class="container">
		<h1>How Building a Terminal Graphics Engine Taught Me About CPU Branch Prediction and Cache Hierarchy
		</h1>

		<p class="subtitle"><strong>Or: Why My "Optimized" Rendering Function Was Sometimes Slower Than My
				"Slow" One</strong></p>

		<hr>

		<h2>The Setup</h2>

		<p>I've been building <strong>movy</strong>, a terminal-based graphics rendering engine in Zig that
			turns your terminal into a graphical canvas using ANSI escape codes and Unicode half-blocks.
			Think of it as a retro game engine, but instead of pixels on a screen, you're drawing colored
			characters in a terminal window.</p>

		<p>Recently, I implemented three different rendering methods for compositing multiple semi-transparent
			surfaces:</p>

		<ol>
			<li><strong><code>render()</code></strong> - The "fast path" with binary transparency (either
				fully opaque or fully transparent)</li>
			<li><strong><code>renderWithAlphaToBg()</code></strong> - Alpha blending optimized for rendering
				to opaque backgrounds</li>
			<li><strong><code>renderWithAlpha()</code></strong> - Full alpha compositing supporting
				semi-transparent backgrounds</li>
		</ol>

		<p>The theory was simple: <code>render()</code> should be fastest (no blending calculations), while the
			alpha methods should be 2-3x slower due to the extra arithmetic. I built a comprehensive
			benchmark suite to prove it.</p>

		<p>Then I ran the tests.</p>

		<p>The results were... bizarre.</p>

		<h2>The Anomaly</h2>

		<div class="image-placeholder">
			<strong>[PLACEHOLDER: Bar chart comparing the three methods for 10x10 sprites with 3 overlapping
				surfaces]</strong>
		</div>

		<p>For tiny 10x10 sprites with 3 overlapping surfaces:</p>

		<pre><code>render(): 1.547 µs/iteration (SLOWEST)
				renderWithAlphaToBg(): 1.089 µs/iteration (42% faster!)
				renderWithAlpha(): 0.856 µs/iteration (81% faster!)</code></pre>

		<p>Wait, what? The "dumb" alpha blending function that does extra multiplication on every pixel is
			beating the "optimized" binary transparency path by almost 2x?</p>

		<p>But it gets weirder. When I tested with 5 overlapping surfaces instead of 3:</p>

		<pre><code>render(): 0.937 µs/iteration (FASTEST)
				renderWithAlphaToBg(): 1.563 µs/iteration
				renderWithAlpha(): 1.276 µs/iteration</code></pre>

		<p>Now <code>render()</code> is fastest again, and it's actually <strong>65% faster with 5 surfaces than
				with 3 surfaces</strong>, despite doing more work!</p>

		<p>Something was very wrong. Either my benchmark was broken, or I was about to learn something
			interesting about modern CPUs.</p>

		<hr>

		<h2>The Investigation</h2>

		<p>Let me show you the core of the <code>render()</code> function:</p>

		<pre><code>for (surfaces) |surface| {
				for (each_pixel_in_surface) |pixel| {
				// Skip transparent pixels
				if (surface.shadow_map[pixel] == 0) continue;

				const idx_out = calculate_output_position(pixel);

				// Only write if destination is not already occupied
				if (out_surface.shadow_map[idx_out] != 1) {
				out_surface.color_map[idx_out] = surface.color_map[pixel];
				out_surface.shadow_map[idx_out] = 1;
				}
				}
				}</code></pre>

		<p>The optimization seems sound: surfaces are z-sorted (front-to-back), and we skip writing to pixels
			that are already drawn. Early exit, avoid redundant work, classic optimization.</p>

		<p>Compare this to the alpha blending version:</p>

		<pre><code>for (surfaces) |surface| {
				for (each_pixel_in_surface) |pixel| {
				if (surface.shadow_map[pixel] == 0) continue;

				const idx_out = calculate_output_position(pixel);

				// ALWAYS blend, regardless of what's there
				const blended = blend_colors(
				surface.color_map[pixel],
				out_surface.color_map[idx_out]
				);
				out_surface.color_map[idx_out] = blended;
				}
				}</code></pre>

		<p>The alpha version does MORE work (multiplication, division) but has NO conditional write. It always
			blends.</p>

		<p>That's the key difference.</p>

		<hr>

		<h2>Branch Prediction: The Hidden Performance Killer</h2>

		<p>Modern CPUs don't execute instructions one at a time. They use <strong>pipelining</strong> -
			fetching, decoding, and executing multiple instructions simultaneously. The Apple M4 in my
			MacBook can have dozens of instructions in flight at once.</p>

		<p>But there's a problem: branches (if statements) create uncertainty. When the CPU encounters a branch,
			it doesn't know which path to take until the condition is evaluated. Waiting would stall the
			pipeline, wasting precious cycles.</p>

		<p>The solution? <strong>Branch prediction</strong>. The CPU <em>guesses</em> which path the branch will
			take and speculatively executes instructions down that path. If the guess is correct, everything
			proceeds at full speed. If wrong, the CPU must throw away all the speculative work and restart
			from the correct path.</p>

		<p>This is called a <strong>branch misprediction</strong>, and on modern processors like the M4, it
			costs roughly 15-20 CPU cycles per misprediction.</p>

		<h3>The Pattern Matters</h3>

		<p>Here's where my test setup matters. I positioned sprites with 5-pixel offsets:</p>

		<pre><code>Surface 0: position (10, 10), z-index 0 (drawn last)
				Surface 1: position (15, 15), z-index 1
				Surface 2: position (20, 20), z-index 2 (drawn first)</code></pre>

		<p>With 10x10 pixel sprites, this creates different overlap patterns depending on how many surfaces you
			have.</p>

		<p><strong>Three surfaces (irregular pattern):</strong></p>

		<pre><code>Surface 2 drawn first: 100% of pixels written (0% already occupied)
				Surface 1 drawn second: 75% of pixels written (25% overlap with surface 2)
				Surface 0 drawn last: 75% of pixels written (25% overlap, but irregular pattern)</code>
		</pre>

		<p>The branch condition <code>if (out_surface.shadow_map[idx_out] != 1)</code> becomes unpredictable.
			For surface 2, it's always false (100% write rate). For surfaces 1 and 0, it's a mix (75% write
			rate), but the pattern of which pixels overlap is irregular.</p>

		<p><strong>Five surfaces (regular pattern):</strong></p>

		<pre><code>Surface 4: 100% written (always false)
				Surface 3: 75% written (predictable pattern)
				Surface 2: 50% written (very predictable - half the pixels)
				Surface 1: 25% written (predictable pattern)
				Surface 0: 0% written (always true - everything overlaps)</code></pre>

		<p>The five-surface pattern creates more <em>regular</em> overlap. The CPU's branch predictor can learn:
			"For this surface at this position, we usually skip/write." The pattern is predictable.</p>

		<div class="image-placeholder">
			<strong>[PLACEHOLDER: Diagram showing overlap patterns for 3 vs 5 surfaces]</strong>
		</div>

		<h3>The Math</h3>

		<p>Let me estimate the branch misprediction cost:</p>

		<ul>
			<li>M4 CPU: ~15-20 cycles per misprediction</li>
			<li>Three-surface test: ~40-50 mispredictions per iteration (estimated)</li>
			<li>At M4's ~4 GHz clock: 40 mispredictions × 15 cycles = 600 cycles ≈ 0.15 µs</li>
		</ul>

		<p>But we're processing 100 pixels twice (surfaces 1 and 0), so the irregular pattern compounds. Total
			overhead: <strong>~0.6 µs</strong>.</p>

		<p>The observed difference: 1.547 µs (3 surfaces) - 0.937 µs (5 surfaces) = <strong>0.61 µs</strong>.
		</p>

		<p>The numbers match perfectly. We're not measuring rendering performance. We're measuring branch
			prediction failure.</p>

		<h3>Why Alpha Blending Wins</h3>

		<p>The alpha blending functions have no conditional write. They always execute the same code path:</p>

		<pre><code>// No branch here!
				out_surface.color_map[idx] = blend(fg_color, bg_color);</code></pre>

		<p>No branches means no mispredictions. For very small sprites (10x10 = 100 pixels) with irregular
			overlap patterns, the cost of branch misprediction exceeds the cost of doing unnecessary
			multiplications.</p>

		<p>This is counterintuitive but profound: <strong>sometimes doing more arithmetic is faster than trying
				to be clever with branches</strong>.</p>

		<hr>

		<h2>The Second Mystery: The Megapixel Curve</h2>

		<p>While investigating the rendering engine, I also benchmarked a separate function:
			<code>toAnsi()</code>, which converts a pixel surface into ANSI escape sequences for terminal
			rendering.</p>

		<p>The throughput measurements showed something unexpected:</p>

		<div class="image-placeholder">
			<strong>[PLACEHOLDER: Line graph of MP/s vs sprite size for toAnsi()]</strong>
		</div>

		<pre><code>Size | Time/iteration | Throughput (MP/s)
				--------|----------------|------------------
				10x10 | 0.268 µs | 373.0 MP/s
				20x20 | 1.140 µs | 350.8 MP/s
				40x40 | 4.749 µs | 336.9 MP/s ← Lowest
				64x64 | 10.712 µs | 382.4 MP/s ← Peak!
				80x80 | 18.655 µs | 343.1 MP/s
				100x100 | 28.467 µs | 351.3 MP/s
				200x200 | 111.850 µs | 357.6 MP/s</code></pre>

		<p>The processing time scales roughly quadratically (as expected for O(n²) algorithms), but the
			throughput isn't monotonic. There's a clear peak at 64x64, with a valley at 40x40.</p>

		<p>Why does performance <em>improve</em> when processing more data?</p>

		<h2>Understanding Cache Hierarchy</h2>

		<p>Modern processors don't access RAM directly for every memory operation. That would be far too slow.
			Instead, they use a hierarchy of increasingly faster (and smaller) caches:</p>

		<p><strong>Apple M4 Cache Structure:</strong></p>

		<ul>
			<li><strong>L1 Cache</strong>: 128 KB per core, ~3-4 cycle latency (fastest)</li>
			<li><strong>L2 Cache</strong>: 4 MB shared, ~12-15 cycle latency</li>
			<li><strong>L3 Cache</strong>: 16 MB shared, ~30-40 cycle latency</li>
			<li><strong>RAM</strong>: 16+ GB, ~100+ cycle latency (slowest)</li>
		</ul>

		<p>When your program accesses memory, the CPU checks L1 first. If the data is there (cache hit), you get
			it in a few cycles. If not (cache miss), the CPU checks L2, then L3, then finally RAM. Each
			level is progressively slower.</p>

		<p>The key insight: <strong>your program's performance is often determined by how well your data fits in
				cache</strong>.</p>

		<h3>The Memory Footprint</h3>

		<p>Each pixel in my rendering engine requires:</p>

		<pre><code>struct Pixel {
				color: RGB, // 3 bytes
				alpha: u8, // 1 byte
				char: u21, // 4 bytes (UTF-8)
				}
				// Total: 8 bytes per pixel</code></pre>

		<p>For different sprite sizes:</p>

		<pre><code>10x10: 100 pixels × 8 bytes = 800 bytes
				40x40: 1,600 pixels × 8 bytes = 12,800 bytes
				64x64: 4,096 pixels × 8 bytes = 32,768 bytes ← Key size!
				80x80: 6,400 pixels × 8 bytes = 51,200 bytes</code></pre>

		<p>Notice anything special about 64x64? It's <strong>32 KB</strong> - roughly a quarter of the 128 KB L1
			cache.</p>

		<p>At this size:</p>

		<ul>
			<li>The entire sprite fits comfortably in L1 cache</li>
			<li>All pixel data stays "hot" during processing</li>
			<li>The CPU can effectively prefetch the next cache line</li>
			<li>Memory access patterns align with 64-byte cache line boundaries</li>
		</ul>

		<h3>Too Small: Overhead Dominates</h3>

		<p>For smaller sprites (40x40 and below), the data fits in cache easily, but another factor dominates:
			<strong>ANSI string generation overhead</strong>.</p>

		<p>The <code>toAnsi()</code> function generates strings like:</p>

		<pre><code>\x1b[38;2;255;0;0m▀\x1b[48;2;0;255;0m</code></pre>

		<p>That's roughly 43 bytes of output per "pixel pair" (two vertical pixels rendered as one half-block
			character). For a 10x10 sprite, you're generating ~2 KB of string data to represent 800 bytes of
			pixel data. The ratio of output to input is unfavorable - string manipulation overhead dominates
			actual pixel processing.</p>

		<h3>Too Large: Cache Thrashing</h3>

		<p>For sprites larger than 64x64, the data no longer fits in L1 cache. An 80x80 sprite needs 51 KB,
			which exceeds L1's capacity. The CPU must fetch data from the slower L2 cache, introducing more
			latency.</p>

		<p>At 200x200 (320 KB of pixel data plus ~860 KB of output string), you're definitely in L2 or even L3
			territory. The memory access pattern becomes less predictable, cache lines get evicted before
			reuse, and overall efficiency drops.</p>

		<div class="image-placeholder">
			<strong>[PLACEHOLDER: Diagram showing memory hierarchy and where different sprite sizes
				land]</strong>
		</div>

		<h3>The Sweet Spot</h3>

		<p>64x64 represents the Goldilocks zone:</p>

		<ul>
			<li>Large enough that string generation overhead is amortized</li>
			<li>Small enough to fit entirely in L1 cache</li>
			<li>Perfect alignment with CPU cache line architecture</li>
			<li>Maximum data reuse and minimal cache misses</li>
		</ul>

		<p>The result: peak throughput of 382 megapixels per second.</p>

		<p>This isn't theoretical. The cache hierarchy is a physical reality of CPU design, and your code's
			performance is directly shaped by how well your data structures align with it.</p>

		<hr>

		<h2>Practical Implications</h2>

		<p>These discoveries have real implications for how I write performance-critical code:</p>

		<h3>1. Profile, Don't Assume</h3>

		<p>My "optimized" early-exit path was slower in some cases. The only way to know is to measure.
			Assumptions about performance are often wrong, especially when they ignore CPU
			microarchitecture.</p>

		<h3>2. Branchless Can Be Faster</h3>

		<p>For small data sets with unpredictable patterns, eliminating branches entirely may outperform clever
			conditional logic. This is especially true when:</p>

		<ul>
			<li>Working with small arrays (&lt; 1000 elements)</li>
			<li>Branches have unpredictable patterns</li>
			<li>The cost of misprediction exceeds the cost of extra work</li>
		</ul>

		<h3>3. Design for Cache Locality</h3>

		<p>Structure your data to fit in cache:</p>

		<ul>
			<li>Keep hot data compact (64x64 is not arbitrary!)</li>
			<li>Process data in cache-friendly patterns</li>
			<li>Consider cache line sizes (64 bytes on most modern CPUs)</li>
			<li>Group related data together in memory</li>
		</ul>

		<h3>4. Different Scales, Different Bottlenecks</h3>

		<p>Performance optimization isn't one-size-fits-all:</p>

		<ul>
			<li><strong>Small data</strong>: Overhead and branches matter most</li>
			<li><strong>Medium data</strong>: Cache locality is king</li>
			<li><strong>Large data</strong>: Memory bandwidth and algorithmic complexity dominate</li>
		</ul>

		<p>The same code can have completely different performance characteristics at different scales.</p>

		<hr>

		<h2>The Bigger Picture</h2>

		<p>Building this rendering engine taught me something fundamental: <strong>modern CPUs are incredibly
				complex, and your high-level code is only part of the performance equation</strong>.</p>

		<p>The CPU's branch predictor, cache hierarchy, speculative execution, and out-of-order execution all
			influence performance in ways that aren't visible in your source code. You're not just writing
			algorithms; you're writing instructions that will be interpreted and transformed by layers of
			hardware optimization.</p>

		<p>This isn't esoteric knowledge for compiler writers. It's practical wisdom for anyone writing
			performance-critical code. A few takeaways:</p>

		<p><strong>Know your working set size.</strong> How much data are you actively using? Does it fit in L1?
			L2? Structure your algorithms to work on cache-sized chunks.</p>

		<p><strong>Know your branch patterns.</strong> Are your conditionals predictable? If not, can you
			eliminate them? Sometimes <code>result = condition * valueA + (1-condition) * valueB</code> is
			faster than <code>if (condition) result = valueA else result = valueB</code>.</p>

		<p><strong>Measure at the right scale.</strong> Testing with 10x10 sprites revealed branch prediction
			issues that would have been invisible at larger sizes. Test across your expected range of
			inputs.</p>

		<p><strong>Trust the profiler, not your intuition.</strong> Your mental model of performance is probably
			wrong. Mine certainly was.</p>

		<hr>

		<h2>Conclusion</h2>

		<p>I set out to build a terminal graphics engine and accidentally built a branch prediction and cache
			profiler.</p>

		<p>The "anomalies" in my benchmark results weren't bugs - they were features, revealing the hidden
			behavior of modern CPUs. The render function that should have been fastest was sometimes
			slowest. The megapixel throughput curved up and down in unexpected ways.</p>

		<p>But these weren't mysteries once I understood what I was actually measuring: not just my code, but
			the interaction between my code and the CPU's microarchitecture.</p>

		<p>Next time you see unexpected benchmark results, don't immediately assume your code is wrong. You
			might be seeing the fingerprints of branch predictors, cache hierarchies, or any number of
			hardware optimizations working in the background.</p>

		<p>Or, like me, you might be learning that sometimes the "slow" path is faster, and 64x64 isn't just a
			nice round number - it's a cache-aligned sweet spot on an Apple M4 processor.</p>

		<hr>

		<p><strong>About the Project</strong>: movy is an open-source terminal graphics engine written in Zig,
			capable of sprite rendering, alpha blending, animation, and effects - all in your terminal
			window. The complete source code and performance analysis are available on GitHub.</p>

		<div class="image-placeholder">
			<strong>[PLACEHOLDER: Screenshot of terminal graphics rendered with movy]</strong>
		</div>

		<hr>

		<div class="footer">
			<p><em>Have you encountered surprising performance characteristics in your code? What did they
					teach you about your hardware? Share your stories in the comments below.</em>
			</p>
		</div>
	</div>
</body>

</html>
